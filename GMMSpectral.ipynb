{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbe3779-46f7-4118-8a1c-7f09fd388a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150fe68-9f08-453c-8a7e-65f58f72ec91",
   "metadata": {},
   "source": [
    "The following cell opens the normalized images and does PCA. This takes several minutes and since we are only interested in using the dimensionality reduced data, this cell should only be run once to write data to a new file, enabling faster loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c0fbbc-969c-474a-9e3b-d840a86ab9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattened_image_dir= \"processed_galaxy_data/flattened_normalized_images.csv\"\n",
    "\n",
    "# #load flattened images\n",
    "# flattened_data = pd.read_csv(flattened_image_dir, header = None)\n",
    "# pca = PCA(n_components = 35)\n",
    "# fitted_pca = pca.fit_transform(flattened_data)\n",
    "# np.savetxt('processed_galaxy_data/pca_normalized.csv', fitted_pca, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e626a9a0-bbb3-44a3-abe0-f4535cf1b313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fitted_pca = pd.read_csv(\"processed_galaxy_data/pca_normalized.csv\", header = None)\n",
    "labels = pd.read_csv(\"processed_galaxy_data/labels_mappings_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfe3b3-4ce3-4bc7-9735-3041786d3386",
   "metadata": {},
   "source": [
    "We want to look into how GMM will cluster our data and its effectiveness. First, we get a random subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb0c248a-6c65-466c-99a1-31823a2d0649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape_label\n",
       "E     97643\n",
       "S     95818\n",
       "SB    45568\n",
       "A       544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(fitted_pca, labels[\"shape_label\"], train_size=0.8, random_state=42)\n",
    "labels[\"shape_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ca738-85a1-48db-83a7-fca0c0a924f3",
   "metadata": {},
   "source": [
    "Next, we declare the GMM and its parameters. Since we know that our data has 4 labels, we can explicitly set `n_components` to 4. GMMs have a parameter to dictate the covariance type to optimize over. We set up a grid search for the multiple types of covariance and cross validate over our randomly chosen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a830ec-4335-4850-97f3-a9adf4da4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 4)\n",
    "pipe_gmm = Pipeline([\n",
    "    (\"gmm\", gmm)\n",
    "])\n",
    "param_grid_gmm = {\n",
    "    \"gmm__covariance_type\": [\"full\", \"tied\", \"spherical\", \"diag\"]\n",
    "}\n",
    "grid_gmm = GridSearchCV(pipe_gmm, param_grid_gmm, scoring = \"adjusted_rand_score\", n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ede9c-b899-42a7-b1ba-72ada945b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_gmm = grid_gmm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d08c88-87ee-4199-9b7f-8c002e795509",
   "metadata": {},
   "source": [
    "We used the Adjusted Rand Index to score our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f3316e-e18f-4b00-ba77-3b99e853a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gmm = pd.DataFrame(grid_gmm.cv_results_['params'] )\n",
    "results_gmm['Mean Adjusted Rand Index'] = grid_gmm.cv_results_['mean_test_score']\n",
    "results_gmm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c79a5-58ed-4f72-ba1f-cd50b78137d4",
   "metadata": {},
   "source": [
    "Our scores are fairly poor -- almost close to 0. The reason for this may be explored more. Let's try another clustering method to see if results are any better.\n",
    "\n",
    "Spectral clustering has the ability to fit non-convex data. However, unlike some other clustering methods, it cannot predict labels -- thus, a cross validation method can't be used.\n",
    "\n",
    "To get around this, we randomly subset our data multiple times and train a Spectral Clustering model on each subset with varying `n_neighbors`. Since Spectral Clustering makes heavy use of adjacency and Laplacian matrices, the time and space complexity is high. A few thousand is relatively representative of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc3043-3334-4da6-8676-0cebe8e47e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_list = [1,5,10,20]\n",
    "spectral_ari = pd.DataFrame(index =  range(4), columns = [1,5,10,20])\n",
    "for i in range(4):\n",
    "    X_train, _, y_train, _ = train_test_split(fitted_pca, labels[\"shape_label\"], train_size=2000, random_state = i)\n",
    "    for nn in nn_list:\n",
    "        spectral = SpectralClustering(n_clusters = 4, n_neighbors = nn)\n",
    "        y_labels = spectral.fit(X_train).labels_\n",
    "        spectral_ari.loc[i, nn] = metrics.adjusted_rand_score(y_labels, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af8b3d5-315f-456a-8492-24b8656aac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_ari"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
