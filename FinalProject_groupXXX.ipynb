{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Complexity of Galaxy Imaging Data\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Kian Chou\n",
    "- Jalen Li\n",
    "- Hana Tse\n",
    "- Arturo Sorensen\n",
    "- Tianran Bao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In this project, we investigate the effectiveness of unsupervised machine learning algorithms on clustering different galaxy shapes using images. To achieve this, we used a dataset containing images of galaxies and various algorithms such as K-means, GMM, Spectral, and DBSCAN to cluster galaxies that had similar shapes. We also ran evaluation metrics such as silhouette score and Adjusted Rand index to assess the performance of the resulting clusters and their corresponding algorithms. Overall, we saw low silhouette and Adjusted Rand scores from each algorithm’s cluster, leading us to believe that unsupervised algorithms are not suitable for this task. However, we believe that the conclusions of our project have been influenced by limitations such as computational load and data complexity, so this problem could be investigated further with more resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Galaxies are fascinating astronomical objects that are extremely numerous and diverse - it’s estimated that there are billions or even possibly trillions of galaxies in the observable universe, each with unique properties/features. They vary in size from being ultra massive to relatively small, with a multitude of shapes such as elliptical (appears as a concentrated elliptic blob), spiral (has a circular twist and arms), and irregular (sparse and not as structured). Some are young and actively growing whereas others are ancient and dormant. As mentioned in our proposed solution, color and luminosity can vary as well. Luminosity can be affected by its age, metallicity, component stars, dust content, distance from the observer, etc. On the other hand, color not only can be affected by composition, but also by redshift; as the universe expands at an accelerated rate, the objects that are farther from us recede faster, which creates a phenomenon called redshift in which the light’s wavelength is stretched (since the universe itself is expanding) and appears redder.\n",
    "\n",
    "The diversity galaxies offer makes them excellent subjects for image classification and exploratory study. Due to this, in recent years, the field of galaxy classification through machine learning not only has seen advancements, but has also greatly helped researchers study these astronomical bodies. Galaxy Zoo is a project that provided visual morphological classification, which refers to categorizing galaxies based on their shape and structure (e.g. spiral, elliptical, irregular), based on galaxy images from the Sloan Digital Sky Survey (SDSS)<a name=\"lintottnote\"></a>[<sup>[1]</sup>](#lintott). The first Galaxy Zoo paper’s aim was to \n",
    "distinguish between the two morphological classes pertaining to massive systems, namely spirals and early-type systems<a name=\"lintottnote\"></a>[<sup>[1]</sup>](#lintott). \n",
    "\n",
    "Galaxy Zoo 2<a name=\"zoo2\"></a>[<sup>[2]</sup>](#zoo2), which is the data we are using, is a succeeding project that considers more detailed morphological features such as \"galactic bars, spiral arm and pitch angle, bulges, edge-on galaxies, relative ellipticities, and many others\"<a name=\"zoosite\"></a>[<sup>[3]</sup>](#zoosite). Moreover, galactic bars refer to the elongated structures composed of stars and interstellar matter that extend from the center of spiral galaxies; pitch angle measures the tightness of spiral arms around a galaxy’s center; bulges are the tightly packed collections of stars at the centers of galaxies; edge-on means observed from the side, which would make the bulge more visible; and relative ellipticity is the galaxy’s deviation from a circular shape.\n",
    "\n",
    "\"There has been much research dedicated to classifying galaxy image data with convolutional neural networks (CNNs), including Huertas et al. using the Cosmic Assembly Near-Infrared Deep Extragalactic Legacy Survey (CANDELS) data to classify over a range of redshifts<a name=\"huertas\"></a>[<sup>[4]</sup>](#huertas). In a similar vein, we will be classifying galaxy image data, but it’s important to note that this isn’t the only way. For example, Krakowski et al. applied a support vector machine (SVM) to tabular data from the WISE × SuperCOSMOS catalog<a name=\"krakowski\"></a>[<sup>[5]</sup>](#krakowski)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Galaxies have a couple of different visual features, including shape, color, luminosity, and concentration. There are a few different ways that galaxies are classified, but the system we will be sticking to will use their morphology. There are 3 main categories of galaxies: elliptical, spiral, and irregular. \n",
    "\n",
    "The problem that we aim to solve is seeing if galaxies can be clustered based on their visual features alone. For this, we will be analyzing the galaxy images in our dataset and use unsupervised learning algorithms to attempt to cluster galaxies by their morphology classification.\n",
    "\n",
    "We will be using PCA and UMAP for dimentionality reduction to transform the data high dimentional image data into lower dimentional space for easier analysis. Then we will use multiple different unsupervised algorithms including K-means, DBSCAN, GMM, Spectral, and PCA reconstruction to a performing clustering on the image data.\n",
    "\n",
    "This problem can be measured in the following two ways. We will first use the crowd-sourced labels in our dataset and seperate a part of our data as test/training data to evaluate the performance of our models. We will also evalutation metrics without using the labels to measure the performance of our clustering algorithms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data Sources\n",
    "The raw galaxy image data can be found at this link: https://zenodo.org/records/3565489#.Y3vFKS-l0eY\n",
    "\n",
    "This dataset has a total of 355,990 images of centered images and the unique ID associated with them.\n",
    "\n",
    "The galaxy image labels can be found at this link: https://data.galaxyzoo.org/#section-7\n",
    "\n",
    "This dataset contains 239,695 image-label pairs, which is less than the amount of images that was present in the zenodo link. \n",
    "\n",
    "## Data Preprocessing\n",
    "To combine the image dataset and label dataset, we paired up the image file name and label using a unique identifier assigned to each galaxy. Through this, we ended up with a combined dataset made up of 239,695 galaxy images and labels. One observation in this dataset was made up of a grainy color image of a target galaxy centered in a 424x424 pixel frame and a corresponding label with galaxy shape and classification. This image can also contain other, smaller galaxies which could prove to be a difficult issue to overcome.  \n",
    "\n",
    "In the following cell, a few samples of the raw images and their filenames are displayed.\n",
    "\n",
    "![unprocessed_images_sample.png](report_images/unprocessed_images_sample.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our overall goal is to be able to classify the shape of a provided 50x50 image of a galaxy. The galaxies can be one of four shapes: elliptical (E), spiral (S), spiral barred (SB), and amorphous (A). The first three types of galaxy occur in about equal frequency, but the amorphous type galaxy happens very rarely, with about 500 observations. \n",
    "\n",
    "A notebook with the code used to preprocess our images can be found at this Github link: https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning.ipynb\n",
    "\n",
    "To preprocess the image data, we first needed to crop the images so they mainly contain the galaxy we want to analyze, grayscale the images, and then scale down the images to reduce the computation necessary to process the data. To crop the data, we took the center 200x200 region of each image. Looking over multiple images, we found that this center dimension usually contained the entire galaxy that was being analyzed. We then grayscaled the images since color data is not as important to analyzing the overall shape of the galaxy. Finally, we scaled the 200x200 image down to a 50x50 image so that we had the computing power to work on the data and the data would not take too long. \n",
    "\n",
    "The images were then flattened into an array of size 2,500 and put into a matrix with all other observations. Each value in this matrix was normalized from a scale of 0 to 255 (representing pixel darkness) to a scale of 0 to 1 by dividing each value in the matrix by 255.\n",
    "\n",
    "This means that our final, processed data has a total of 239,695 observations, with each observation containing a 50x50 image and a label for what the overall shape of the galaxy is. This means that each observation has a total of 2,500 critical variables.\n",
    "\n",
    "In the following cell, a few samples of the processed images and their filenames are displayed.![processed_images_sample.png](report_images/processed_images_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The principal problem we aim to tackle for this project is whether labeling galaxy shapes through the differences in their images is feasible.\n",
    "\n",
    "The different galaxy shapes in images involve variance in several properties, such as luminosity and distribution of pixels. We plan to cast image data into a uniform format by grayscaling the colors, as well as reducing resolution by cropping to the center, removing uninformative black space in the process. From there, a normalized set of vectors representing the grayscale, centered image (1 x 2500) can be run through dimensionality reduction methods, such as UMAP and PCA. Once a large amount of variance can be explained in a lower amount of dimensions, our projected data will enter various clustering algorithms such as K-means, DBSCAN, Spectral, and GMMs. We will then evaluate the performance of each clustering algorithm’s results to answer our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The Galaxy Zoo project, from which our data is obtained, has crowd-sourced labels for each galaxy. Each label is derived from a contribution of around 100,000 volunteers, reducing biases and ultimately providing a robust, confident classification (https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L/abstract). \n",
    "\n",
    "There are a few metrics for the goodness-of-fit of clustering algorithms. For one, we can score our clusters using their Silhouette score, ranging from -1 to 1. The silhouette score can be interpreted from having poorly assigned clusters, to overlapping clusters at 0, to well-assigned and separated clusters. Since our dataset also contains correct labels, we can use the Adjusted Rand Index (ARI) to score our clusters. The ARI computes how well the cluster assignments are and ranges from -0.5 to 1, with -0.5 being poor and 1 being exact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Galaxy Imaging: A Very Complex Problem\n",
    "\n",
    "Throughout the course of this project, we began to uncover how complex of a task classifying images in the GalaxyZoo 2 dataset was. From attempts at both PCA and KPCA to [other technique] to [other technique], each attempt uncovered more and more facets of the dataset that each technique struggled with. Although we were not able to come up with a conclusive process for clustering or classifying these images, with each technique we tried, were able to get a deeper understanding of what makes this dataset difficult and what future techniques that can be employed to classify the images in this dataset.\n",
    "\n",
    "### Visually Analyizing the Images: Overlap and Noise\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- Data Cleaning and PCA notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning_and_PCA.ipynb)   \n",
    "\n",
    "From taking a look at the processed images, we realized how subtle the difference between the images were for galaxies of different categories for humans, let alone for an algorithm. \n",
    "\n",
    "![similar_galaxy_examples.png](report_images/similar_galaxy_examples.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>From left to right: an ellipitcal (E) galaxy, a spiral (S) galaxy, and a spiral barred (SB) galaxy.</i></p>\n",
    "\n",
    "This led to some concerns as to how well these subtle features would be represented in a dimensionality reduction, as we would not have the time nor computing power to process the entire 2,500 variables for each image, but we figured that it would be worth exploring to see what we could find. \n",
    "\n",
    "Another issue that we could find is that most of the images in this dataset had non-relevant galaxies present in the same frame as the galaxy we wanted to analyze. This combined with the subtlety of the features that differentiate the galaxies from each other lead to a difficult situation where both the noise and signal comes from variance between different samples. Despite this, we hoped that with a lot of images, the variance from the irrelevant galaxies would not have too much impact on the classification.\n",
    "\n",
    "### PCA: Linearly Unseperable Data [UNFINISHED]\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- Data Cleaning and PCA notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning_and_PCA.ipynb)   \n",
    "\n",
    "To reduce the computational load of the data, we performed a PCA on all of the flattened 50x50 grayscale images to evaluate which components contributed to the most variance in the dataset. We plotted the variance explained by each component and decided to cut at the eblow to find the amount of principal components that explained the most amount of variance between images. \n",
    "\n",
    "![PCA_elbow.png](report_images/PCA_elbow.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>A graph outlining how much variance is explained by the first 200 principal components. The red dashed line is drawn at principal component 35.</i></p>\n",
    "\n",
    "Further clustering was then done on these 35 principal components, including UMAP, K-means, DBSCAN, GMM, and spectral clustering. \n",
    "\n",
    "### UMAP\n",
    "\n",
    "Another dimensionality reduction technique we tried to use was UMAP. From the flattened 50x50 images, we tried a couple of different iterations of UMAP with different parameters but generally ended up with the same results each time. Below are the plotted results from using `n_neighbors=25` and `min_dist=0.05`.\n",
    "\n",
    "![UMAP_plot.png](report_images/UMAP_plot.png)\n",
    "\n",
    "From this plot, we see that there is little to get from these results. There aren’t any well-defined clusters where certain galaxy types group up. Therefore, we decided to stick with the results from PCA to use as our dimensionally reduced data.\n",
    "\n",
    "#### K-Means:\n",
    "*The results discussed in this section can be found in the following notebooks:*\n",
    "- K-Means Notebook (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/K-means.ipynb).\n",
    "- K-means, GMM, HDBSCAN, Hierarchical Clustering notebook (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/PCA_KMeans_GMM_HDBSCAN_HierarchicalFail_UMAP.ipynb)\n",
    "\n",
    "#### GMM:\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- GMM and Spectral Clustering notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/GMMSpectral.ipynb)\n",
    "\n",
    "Gaussian Mixture Models operate under the assumption that data can be multivariate and normally distributed (Gaussian) with different types of covariances. An attempt was made to run GMM clustering on the PCA data, scored using the Adjusted Rand Index which was mentioned in the Evaluation Metric section.\n",
    "\n",
    "![GMM_results_table.png](report_images/GMM_results_table.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>The mean ARI score for each covariance type allowed in GMMs is close to 0. Changing the covariance does not affect results meaningfully.</i></p>\n",
    "\n",
    "This result tells us that the data may not Gaussian distributed, or that the data may be too dense to properly separate out.\n",
    "\n",
    "#### Spectral Clustering:\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- GMM and Spectral Clustering notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/GMMSpectral.ipynb)\n",
    "\n",
    "Spectral clustering works by creating similarity matrices of the data and using an approximate optimal cut on a Laplacian matrix to estimate similar clusters. In order to examine this clustering technique without massive time and memory overhead, we took random samples of our data, fitted a spectral clustering algorithm, and scored each clustering assignment using the Adjusted Rand Index.\n",
    "\n",
    "![Spectral_results_table.png](report_images/Spectral_results_table.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>The ARI score table for spectral clustering. Each row is a random subset of our data and the columns indicate how many nearest neighbors were passed to the algorithm.</i></p>\n",
    "\n",
    "Since spectral clustering relies heavily on whether points can be deemed similar or not, one interpretation of the poor results is that the image vectors used are too similar. If data is too close in features, then local clusters are created with no seperation of labels.\n",
    "\n",
    "#### DBSCAN and HDBSCAN:\n",
    "\n",
    "#### Hierarchical:\n",
    "\n",
    "### KPCA: Non-Linearly Unseperable Data\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- Kernel PCA and various clusterings notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/KernelPCA.ipynb)\n",
    "\n",
    "All of the previous clustering algorithms were fitted on dimension reduced via PCA data. However, PCA is purely a linear operator. If the data contains some sort of nonlinear structure, PCA would not be able to capture the variance of the data in a meaningful way. Instead, Kernel-based PCA projects data to a higher dimensional structure, then doing PCA to try and capture variance.\n",
    "\n",
    "We attempted both KernelPCA using a `radial` basis and a `polynomial` basis, then clustered using GMM and DBSCAN to see our results.\n",
    "![Kernel_GMM_results_table.png](report_images/Kernel_GMM_results_table.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>One example of our results - first using a radial basis, then applying GMM clustering to the new data.</i></p>\n",
    "\n",
    "Despite KernelPCA offering a more powerful dimensionality reduction that can fit nonlinear data, we get similarly poor results. This lead us to further hypothesize more about the structure of our data, and whether it was possible to cleanly separate the various galaxy shapes, given the data and algorithms at our disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result [UNFINISHED]\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "One limitation regarding the data was the amount of images per galaxy shape. The “E” and “S” shapes had around 95,000 corresponding images each, but the “SB” shape had around 45,000 images and the “A” shape only had 544 images. The uneven distribution of images affected the algorithms we used, as it was more difficult to cluster and represent the shapes with less data and similarly, could have introduced bias towards the shapes with more representation. \n",
    "\n",
    "On a larger scale, one of the major limitations for our project was computational load. The dataset that we used consisted of more than 230,000 424x424 images and their labels, so if we did not reduce the features in our data, it would have taken excessive time and computational load to run our algorithms. As a result we performed dimensionality reduction in order to reduce the computational costs. However, by reducing the dimensions of our data with PCA, we were working with images that had potentially lost relevant information regarding their shapes. Ideally, we would be able to run our algorithms on the data with all of their original features for more accurate clustering performance, but this was not possible given the computational constraints. \n",
    "\n",
    "Another larger limitation for our project was time. We noticed that a fair amount of our data contained noise due to extraneous planets and stars in the background of the images, but we did not have time to investigate how and to what extent the noise affected our PCA results. The noise in our data could have added variance that was not related to the structure of the galaxy shapes, which in turn could have affected the calculation of the principal components and the models using the resulting PCA data.\n",
    "   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "The dataset that we used contains images and labels that are provided publicly by Galaxy Zoo. Since this data is public and does not pertain to any individuals, it does not present any privacy concerns. Similarly, the aim of our project does not pose any privacy concerns, as our focus was to classify galaxy types using this data. \n",
    "\n",
    "However, there is an ethical concern regarding misinformation. The labels for the images in our dataset are crowdsourced, which has potential for bias. The volunteers that contribute to the labels come from various backgrounds with different levels of experience, so different people might label certain images differently. As a result, there is a risk that the data might not be entirely accurate. In turn, the results of our model may not be accurate either. Therefore, people who view our project should keep in mind that our model might not classify each image correctly and should consider using other sources to verify information that is presented. \n",
    "\n",
    "### Conclusion [UNFINISHED]\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lintottnote\"></a>1.[^](#lintott): Lintott, Chris J., et al. (Sept 2008) Galaxy Zoo: morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey. *Monthly Notices of the Royal Astronomical Society*. https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L<br>\n",
    "<a name=\"zoo2\"></a>2.[^](#zoo2): Willett, Kyle W., et al. (Nov 2013) Galaxy Zoo 2: Images from Original Sample. *Monthly Notices of the Royal Astronomical Society*. https://zenodo.org/records/3565489<br>\n",
    "<a name=\"zoosite\"></a>3.[^](#zoosite): Galaxy Zoo 2, https://data.galaxyzoo.org/#section-7<br>\n",
    "<a name=\"huertas\"></a>4.[^](#huertas): Huertas, M., et al. (Nov 2015) A Catalog of Visual-Like Morphologies in the 5 CANDELS Fields Using Deep Learning. *The Astrophysical Journal*. https://iopscience.iop.org/article/10.1088/0067-0049/221/1/8/pdf<br>\n",
    "<a name=\"krakowski\"></a>5.[^](#krakowski): Krakowski, T., et al. (Aug 2016) Machine-learning identification of galaxies in the WISE x SuperCOSMOS all-sky catalogue. *Astronomy & Astrophysics*. https://www.aanda.org/articles/aa/pdf/2016/12/aa29165-16.pdf<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
