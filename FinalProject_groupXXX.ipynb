{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Complexity of Galaxy Imaging Data\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Kian Chou\n",
    "- Jalen Li\n",
    "- Hana Tse\n",
    "- Arturo Sorensen\n",
    "- Tianran Bao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In this project, we investigate the effectiveness of unsupervised machine learning algorithms on clustering different galaxy shapes using images. To achieve this, we used a dataset containing images of galaxies and various algorithms such as K-means, GMM, Spectral, and DBSCAN to cluster galaxies that had similar shapes. We also ran evaluation metrics such as silhouette score and Adjusted Rand index to assess the performance of the resulting clusters and their corresponding algorithms. Overall, we saw low silhouette and Adjusted Rand scores from each algorithm’s cluster, leading us to believe that unsupervised algorithms are not suitable for this task. However, we believe that the conclusions of our project have been influenced by limitations such as computational load and data complexity, so this problem could be investigated further with more resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Galaxies are fascinating astronomical objects that are extremely numerous and diverse - it’s estimated that there are billions or even possibly trillions of galaxies in the observable universe, each with unique properties/features. They vary in size from being ultra massive to relatively small, with a multitude of shapes such as elliptical (appears as a concentrated elliptic blob), spiral (has a circular twist and arms), and irregular (sparse and not as structured). Some are young and actively growing whereas others are ancient and dormant. As mentioned in our proposed solution, color and luminosity can vary as well. Luminosity can be affected by its age, metallicity, component stars, dust content, distance from the observer, etc. On the other hand, color not only can be affected by composition, but also by redshift; as the universe expands at an accelerated rate, the objects that are farther from us recede faster, which creates a phenomenon called redshift in which the light’s wavelength is stretched (since the universe itself is expanding) and appears redder.\n",
    "\n",
    "The diversity galaxies offer makes them excellent subjects for image classification and exploratory study. Due to this, in recent years, the field of galaxy classification through machine learning not only has seen advancements, but has also greatly helped researchers study these astronomical bodies. Galaxy Zoo is a project that provided visual morphological classification, which refers to categorizing galaxies based on their shape and structure (e.g. spiral, elliptical, irregular), based on galaxy images from the Sloan Digital Sky Survey (SDSS)<a name=\"lintottnote\"></a>[<sup>[1]</sup>](#lintott). The first Galaxy Zoo paper’s aim was to \n",
    "distinguish between the two morphological classes pertaining to massive systems, namely spirals and early-type systems<a name=\"lintottnote\"></a>[<sup>[1]</sup>](#lintott). \n",
    "\n",
    "Galaxy Zoo 2<a name=\"zoo2\"></a>[<sup>[2]</sup>](#zoo2), which is the data we are using, is a succeeding project that considers more detailed morphological features such as \"galactic bars, spiral arm and pitch angle, bulges, edge-on galaxies, relative ellipticities, and many others\"<a name=\"zoosite\"></a>[<sup>[3]</sup>](#zoosite). Moreover, galactic bars refer to the elongated structures composed of stars and interstellar matter that extend from the center of spiral galaxies; pitch angle measures the tightness of spiral arms around a galaxy’s center; bulges are the tightly packed collections of stars at the centers of galaxies; edge-on means observed from the side, which would make the bulge more visible; and relative ellipticity is the galaxy’s deviation from a circular shape.\n",
    "\n",
    "\"There has been much research dedicated to classifying galaxy image data with convolutional neural networks (CNNs), including Huertas et al. using the Cosmic Assembly Near-Infrared Deep Extragalactic Legacy Survey (CANDELS) data to classify over a range of redshifts<a name=\"huertas\"></a>[<sup>[4]</sup>](#huertas). In a similar vein, we will be classifying galaxy image data, but it’s important to note that this isn’t the only way. For example, Krakowski et al. applied a support vector machine (SVM) to tabular data from the WISE × SuperCOSMOS catalog<a name=\"krakowski\"></a>[<sup>[5]</sup>](#krakowski)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement [UNFINISHED]\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data Sources\n",
    "The raw galaxy image data can be found at this link: https://zenodo.org/records/3565489#.Y3vFKS-l0eY\n",
    "\n",
    "This dataset has a total of 355,990 images of centered images and the unique ID associated with them.\n",
    "\n",
    "The galaxy image labels can be found at this link: https://data.galaxyzoo.org/#section-7\n",
    "\n",
    "This dataset contains 239,695 image-label pairs, which is less than the amount of images that was present in the zenodo link. \n",
    "\n",
    "## Data Preprocessing\n",
    "To combine the image dataset and label dataset, we paired up the image file name and label using a unique identifier assigned to each galaxy. Through this, we ended up with a combined dataset made up of 239,695 galaxy images and labels. One observation in this dataset was made up of a grainy color image of a target galaxy centered in a 424x424 pixel frame and a corresponding label with galaxy shape and classification. This image can also contain other, smaller galaxies which could prove to be a difficult issue to overcome.  \n",
    "\n",
    "In the following cell, a few samples of the raw images and their filenames are displayed.\n",
    "\n",
    "![unprocessed_images_sample.png](report_images/unprocessed_images_sample.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our overall goal is to be able to classify the shape of a provided 50x50 image of a galaxy. The galaxies can be one of four shapes: elliptical (E), spiral (S), spiral barred (SB), and amorphous (A). The first three types of galaxy occur in about equal frequency, but the amorphous type galaxy happens very rarely, with about 500 observations. \n",
    "\n",
    "A notebook with the code used to preprocess our images can be found at this Github link: https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning.ipynb\n",
    "\n",
    "To preprocess the image data, we first needed to crop the images so they mainly contain the galaxy we want to analyze, grayscale the images, and then scale down the images to reduce the computation necessary to process the data. To crop the data, we took the center 200x200 region of each image. Looking over multiple images, we found that this center dimension usually contained the entire galaxy that was being analyzed. We then grayscaled the images since color data is not as important to analyzing the overall shape of the galaxy. Finally, we scaled the 200x200 image down to a 50x50 image so that we had the computing power to work on the data and the data would not take too long. \n",
    "\n",
    "The images were then flattened into an array of size 2,500 and put into a matrix with all other observations. Each value in this matrix was normalized from a scale of 0 to 255 (representing pixel darkness) to a scale of 0 to 1 by dividing each value in the matrix by 255.\n",
    "\n",
    "This means that our final, processed data has a total of 239,695 observations, with each observation containing a 50x50 image and a label for what the overall shape of the galaxy is. This means that each observation has a total of 2,500 critical variables.\n",
    "\n",
    "In the following cell, a few samples of the processed images and their filenames are displayed.![processed_images_sample.png](report_images/processed_images_sample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The principal problem we aim to tackle for this project is whether labeling galaxy shapes through the differences in their images is feasible.\n",
    "\n",
    "The different galaxy shapes in images involve variance in several properties, such as luminosity and distribution of pixels. We plan to cast image data into a uniform format by grayscaling the colors, as well as reducing resolution by cropping to the center, removing uninformative black space in the process. From there, a normalized set of vectors representing the grayscale, centered image (1 x 2500) can be run through dimensionality reduction methods, such as UMAP and PCA. Once a large amount of variance can be explained in a lower amount of dimensions, our projected data will enter various clustering algorithms such as K-means, DBSCAN, Spectral, and GMMs. We will then evaluate the performance of each clustering algorithm’s results to answer our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The Galaxy Zoo project, from which our data is obtained, has crowd-sourced labels for each galaxy. Each label is derived from a contribution of around 100,000 volunteers, reducing biases and ultimately providing a robust, confident classification (https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L/abstract). \n",
    "\n",
    "There are a few metrics for the goodness-of-fit of clustering algorithms. For one, we can score our clusters using their Silhouette score, ranging from -1 to 1. The silhouette score can be interpreted from having poorly assigned clusters, to overlapping clusters at 0, to well-assigned and separated clusters. Since our dataset also contains correct labels, we can use the Adjusted Rand Index (ARI) to score our clusters. The ARI computes how well the cluster assignments are and ranges from -0.5 to 1, with -0.5 being poor and 1 being exact. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Galaxy Imaging: A Very Complex Problem\n",
    "\n",
    "Throughout the course of this project, we began to uncover how complex of a task classifying images in the GalaxyZoo 2 dataset was. From attempts at both PCA and KPCA to [other technique] to [other technique], each attempt uncovered more and more facets of the dataset that each technique struggled with. Although we were not able to come up with a conclusive process for clustering or calssifying these images, with each technique we tried, were able to get a deeper understanding of what makes this dataset difficult and what future techniques that can be employed to classify the images in this dataset.\n",
    "\n",
    "### Visually Analyizing the Images: Overlap and Noise\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- Data Cleaning and PCA notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning_and_PCA.ipynb)   \n",
    "\n",
    "From taking a look at the processed images, we realized how subtle the difference between the images were for galaxies of different categories for humans, let alone for an algorithm. \n",
    "\n",
    "![similar_galaxy_examples.png](report_images/similar_galaxy_examples.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>From left to right: an ellipitcal (E) galaxy, a spiral (S) galaxy, and a spiral barred (SB) galaxy.</i></p>\n",
    "\n",
    "This led to some concerns as to how well these subtle features would be represented in a dimensionality reduction, as we would not have the time nor computing power to process the entire 2,500 variables for each image, but we figured that it would be worth exploring to see what we could find. \n",
    "\n",
    "Another issue that we could find is that most of the images in this dataset had non-relevant galaxies present in the same frame as the galaxy we wanted to analyze. This combined with the subtlety of the features that differentiate the galaxies from each other lead to a difficult situation where both the noise and signal comes from variance between different samples. Despite this, we hoped that with a lot of images, the variance from the irrelevant galaxies would not have too much impact on the classification.\n",
    "\n",
    "### PCA: Linearly Unseperable Data [UNFINISHED]\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- Data Cleaning and PCA notebook: (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/Data_Cleaning_and_PCA.ipynb)   \n",
    "\n",
    "To reduce the computational load of the data, we performed a PCA on all of the flattened 50x50 grayscale images to evaluate which components contributed to the most variance in the dataset. We plotted the variance explained by each component and decided to cut at the eblow to find the amount of principal components that explained the most amount of variance between images. \n",
    "\n",
    "![PCA_elbow.png](report_images/PCA_elbow.png)\n",
    "\n",
    "<p style=\"text-align: center;\"><i>A graph outlining how much variance is explained by the first 200 principal components. The red dashed line is drawn at principal component 35.</i></p>\n",
    "\n",
    "Further clustering was then done on these 35 principal components, including UMAP, K-means, DBSCAN, GMM, and spectral clustering. \n",
    "\n",
    "#### K-Means:\n",
    "*The results discussed in this section can be found in the following notebooks:*\n",
    "- K-Means Notebook (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/K-means.ipynb).\n",
    "- K-means, GMM, HDBSCAN, Hierarchical Clustering notebook (https://github.com/TianranBaoUCSD/COGS118_Final_Project_Group_XXX/blob/main/PCA_KMeans_GMM_HDBSCAN_HierarchicalFail_UMAP.ipynb)\n",
    "\n",
    "#### GMM:\n",
    "*The results discussed in this section can be found in the following notebook:*\n",
    "- \n",
    "\n",
    "#### Spectral Clustering:\n",
    "\n",
    "#### DBSCAN and HDBSCAN:\n",
    "\n",
    "#### Hierarchical:\n",
    "\n",
    "### KPCA: Non-Linearly Unseperable Data [UNFINISHED]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result [UNFINISHED]\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "One limitation regarding the data was the amount of images per galaxy shape. The “E” and “S” shapes had around 95,000 corresponding images each, but the “SB” shape had around 45,000 images and the “A” shape only had 544 images. The uneven distribution of images affected the algorithms we used, as it was more difficult to cluster and represent the shapes with less data and similarly, could have introduced bias towards the shapes with more representation. \n",
    "\n",
    "On a larger scale, one of the major limitations for our project was computational load. The dataset that we used consisted of more than 230,000 424x424 images and their labels, so if we did not reduce the features in our data, it would have taken excessive time and computational load to run our algorithms. As a result we performed dimensionality reduction in order to reduce the computational costs. However, by reducing the dimensions of our data with PCA, we were working with images that had potentially lost relevant information regarding their shapes. Ideally, we would be able to run our algorithms on the data with all of their original features for more accurate clustering performance, but this was not possible given the computational constraints. \n",
    "\n",
    "Another larger limitation for our project was time. We noticed that a fair amount of our data contained noise due to extraneous planets and stars in the background of the images, but we did not have time to investigate how and to what extent the noise affected our PCA results. The noise in our data could have added variance that was not related to the structure of the galaxy shapes, which in turn could have affected the calculation of the principal components and the models using the resulting PCA data.\n",
    "   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "The dataset that we used contains images and labels that are provided publicly by Galaxy Zoo. Since this data is public and does not pertain to any individuals, it does not present any privacy concerns. Similarly, the aim of our project does not pose any privacy concerns, as our focus was to classify galaxy types using this data. \n",
    "\n",
    "However, there is an ethical concern regarding misinformation. The labels for the images in our dataset are crowdsourced, which has potential for bias. The volunteers that contribute to the labels come from various backgrounds with different levels of experience, so different people might label certain images differently. As a result, there is a risk that the data might not be entirely accurate. In turn, the results of our model may not be accurate either. Therefore, people who view our project should keep in mind that our model might not classify each image correctly and should consider using other sources to verify information that is presented. \n",
    "\n",
    "### Conclusion [UNFINISHED]\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lintottnote\"></a>1.[^](#lintott): Lintott, Chris J., et al. (Sept 2008) Galaxy Zoo: morphologies derived from visual inspection of galaxies from the Sloan Digital Sky Survey. *Monthly Notices of the Royal Astronomical Society*. https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L<br>\n",
    "<a name=\"zoo2\"></a>2.[^](#zoo2): Willett, Kyle W., et al. (Nov 2013) Galaxy Zoo 2: Images from Original Sample. *Monthly Notices of the Royal Astronomical Society*. https://zenodo.org/records/3565489<br>\n",
    "<a name=\"zoosite\"></a>3.[^](#zoosite): Galaxy Zoo 2, https://data.galaxyzoo.org/#section-7<br>\n",
    "<a name=\"huertas\"></a>4.[^](#huertas): Huertas, M., et al. (Nov 2015) A Catalog of Visual-Like Morphologies in the 5 CANDELS Fields Using Deep Learning. *The Astrophysical Journal*. https://iopscience.iop.org/article/10.1088/0067-0049/221/1/8/pdf<br>\n",
    "<a name=\"krakowski\"></a>5.[^](#krakowski): Krakowski, T., et al. (Aug 2016) Machine-learning identification of galaxies in the WISE x SuperCOSMOS all-sky catalogue. *Astronomy & Astrophysics*. https://www.aanda.org/articles/aa/pdf/2016/12/aa29165-16.pdf<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
